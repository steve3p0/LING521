{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## LING 521: Applied English Grammar\n",
    "### Text Analysis Script #1 \n",
    "TODO: write up an intro\n",
    "\n",
    "### 1. Load Dependencies\n",
    "Import the required packages (install them if you haven't already)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verify software dependencies loaded: "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "print(sys.version)\n",
    "print(\"My library versions:\")\n",
    "print(f\"matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"ntlk: {nltk.__version__}\")\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "\n",
    "#print(f\"Pandas: {pd.__version__}\")\n",
    "#print(f\"Scipy: {sp.__version__}\")\n",
    "#print(f\"nose: {nose.__version__}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Load Natural Language Processing Tool Kit (NLTK) Package\n",
    "\n",
    "NLTK POS Taggers:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Load Corpora:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# tagset_upenn = nltk.help.upenn_tagset()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "aux_verbs = ['be', 'am', 'are', 'is', 'was', 'were', 'being', 'been',\n",
    "             'can', 'could', 'dare',\n",
    "             'do', 'does', 'did',\n",
    "             'have', 'has', 'had', 'having',\n",
    "             'may', 'might', 'must', 'need', 'ought', 'shall', 'should', 'will', 'would']\n",
    "coordinators = ['and', 'or', 'but', 'nor']\n",
    "\n",
    "adverbs = ['then', 'why']\n",
    "\n",
    "messages = ['Gym?',\n",
    "            'yeah be there in about a half',\n",
    "            'Ok see you when you get here!',\n",
    "            'Seconds away',\n",
    "            'Meet me between smith and cramer asap',\n",
    "            'I got you and Taylor tix in pit section.',\n",
    "            'Get some milk please',\n",
    "            'Chk email',\n",
    "            'Made it',\n",
    "            'Do u know where u saved that movie on my compute',\n",
    "            'Im meeting some dude from the internet for happy hour ahh!',\n",
    "            'Wed is dinner for renetta call us soon',\n",
    "            'where r u???',\n",
    "            'pinball']\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Tag POS in 2007 Text Messages:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "counter_list = []\n",
    "for msg in messages:\n",
    "    tokens = nltk.word_tokenize(msg)\n",
    "    #print(tokens)\n",
    "    pos = nltk.pos_tag(tokens, tagset='universal')\n",
    "    print(f\"\\nmessage: {pos}\")\n",
    "\n",
    "\n",
    "    lstops = [x.lower() for x in stops]\n",
    "    function_words = [word for word in tokens if word in lstops]\n",
    "    fw_count = len(function_words)\n",
    "    print(f\"Function Words: {fw_count}\")\n",
    "\n",
    "    count = Counter([j for i,j in pos])\n",
    "    counter_list.append(count)\n",
    "    print(f\"count: {count}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sum of totals:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "counter_pos = sum(counter_list, Counter())\n",
    "print(f\"\\nCounts: {counter_pos}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.  Plot Stacked Bar Chart\n",
    "Test Graph:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "N = 5\n",
    "menMeans = (20, 35, 30, 35, 27)\n",
    "womenMeans = (25, 32, 34, 20, 25)\n",
    "menStd = (2, 3, 4, 1, 2)\n",
    "womenStd = (3, 5, 2, 3, 3)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, menMeans, width, yerr=menStd)\n",
    "p2 = plt.bar(ind, womenMeans, width,\n",
    "             bottom=menMeans, yerr=womenStd)\n",
    "\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by group and gender')\n",
    "plt.xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "plt.yticks(np.arange(0, 81, 10))\n",
    "plt.legend((p1[0], p2[0]), ('Men', 'Women'))\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.  Summary\n",
    "Summary Write-up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Footer: used to force updates\n",
    "Last Updated: 11/7/2019 1:02 PM "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}